{"data":{"site":{"siteMetadata":{"title":"La gaceta de la cabeza","author":"Joaquín Bravo Contreras","disqusShortname":"gaceta-de-la-cabeza"}},"markdownRemark":{"id":"1a7ad4e7-035e-53b6-be9b-7d88006399f1","excerpt":"Un cliente me tiene que mandar varias imágenes (logotipos, fotos) para poner en el sitio web que les estamos haciendo y lo que se le hizo…","html":"<p>Un cliente me tiene que mandar varias imágenes (logotipos, fotos) para poner en el sitio web que les estamos haciendo y lo que se le hizo más fácil fue subirlo todo a una carpeta en el servidor web que tienen contratado. Me dice que tiene más cosas y que las va a ir subiendo durante la semana.</p>\n<p>Yo quiero bajarlo todo, pero que flojera hacerlo archivo por archivo. Y luego queda el problema de estar revisando la página por archivos nuevos. Tanto trabajo manual va a reducir mi productividad y no podré estar checando mi Google Reader. Por suerte estamos en linux ;-)</p>\n<p>GNU/Linux tiene una herramienta que queda como anillo al dedo para este tipo de tareas y se llama <a href=\"http://www.gnu.org/software/wget/\">wget</a>. Sirve para bajar archivos de Internet y soporta HTTP, HTTPS y FTP. Como dice en su <a href=\"http://www.gnu.org/software/wget/manual/\">documentación</a>, sus principales ventajas son:</p>\n<ul>\n<li>que no es <em>interactivo</em>, lo que permite utilizarlo sin necesidad de intervención por el usuario ;-)</li>\n<li>te permite continuar descargas canceladas (para cuando se te cae la conexión por usar la wifi)</li>\n<li>sabe distinguir entre archivos que ya bajaste y los nuevos de la página</li>\n<li>es recursivo (te podrías bajar todo un sitio web completito con un solo comando)</li>\n</ul>\n<p>Entonces, manos a la obra.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\">\n      <pre class=\"language-text\"><code class=\"language-text\">wget -r -l1 -np -nd -A.jpg,.png,.gif -N http://dominiodelcliente.com/folder_de_imagenes/</code></pre>\n      </div>\n<p>Este comando lo que hace es:</p>\n<ul>\n<li><strong>-r</strong>. bajar todo lo que este en la dirección recursivamente, es decir, seguir todas las ligas que aparezcan en la página (recursive)</li>\n<li><strong>-l1</strong>. pero sólo hasta un nivel de recursividad, es decir, sin seguir las ligas que aparezcan en las otras páginas que se baje (level 1)</li>\n<li><strong>-np</strong>. Sin bajarse los archivos de carpetas en niveles superiores (no parent)</li>\n<li><strong>-nd</strong>. Bajandolo todo en un sólo directorio (no directories)</li>\n<li><strong>-A</strong>. Bajando solamente los archivos que terminen en .gif o .png o .jpg. (Accept)</li>\n<li><strong>-N</strong>. Y bajando solamente los archivos nuevos que no existan ya en la carpeta a menos que el del servidor sea más nuevo</li>\n</ul>\n<p>Este archivo lo puedo correr una vez al día, o ponerlo en el <a href=\"http://es.wikipedia.org/wiki/Cron_(unix)\">cron</a> y me bajara cada vez los archivos nuevos que vaya encontrando. Chido.</p>\n<p>Todo esto fue fácil de averiguar gracias al poder de google, este <a href=\"http://www.veen.com/jeff/archives/000573.html\">buen tutorial</a> escrito en inglés y el man page de wget.</p>","frontmatter":{"title":"Usando wget para bajar canciones o imágenes","date":"December 05, 2008","tags":["linux","consola"]}}},"pageContext":{"slug":"/usando-wget-para-bajar-canciones-o-imagenes/","previous":{"fields":{"slug":"/me-robaron-mi-bicicleta/"},"frontmatter":{"title":"Me robaron mi bicicleta","aliases":[],"tags":["bicicleta"]}},"next":{"fields":{"slug":"/crear-un-nuevo-proyecto-compartido-en-git/"},"frontmatter":{"title":"Crear un nuevo proyecto compartido en git","aliases":[],"tags":["git"]}}}}